# -*- coding: utf-8 -*-
import pandas as pd
import re
from rapidfuzz import process, fuzz
import io
import streamlit as st
import os
import json # Novo import para manipula√ß√£o de JSON

# --- Configura√ß√µes Iniciais da P√°gina ---
st.set_page_config(
    page_title="Circuit Flow Completo",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CONFIGURA√á√ÉO DO DICION√ÅRIO FIXO ---
DICTIONARY_FILE = 'address_dictionary.json' # Nome do arquivo que ser√° salvo/carregado

def load_dictionary(filepath):
    """Carrega o dicion√°rio de corre√ß√µes do arquivo JSON."""
    if not os.path.exists(filepath):
        st.warning(f"Aviso: Arquivo de dicion√°rio '{filepath}' n√£o encontrado. Criando um novo.")
        return {}
    try:
        # Tenta carregar o dicion√°rio
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError:
        st.error(f"Erro: O arquivo '{filepath}' est√° corrompido ou vazio. Retornando dicion√°rio vazio.")
        return {}
    except Exception as e:
        st.error(f"Erro ao carregar o dicion√°rio: {e}")
        return {}

def save_dictionary(filepath, data):
    """Salva o dicion√°rio de corre√ß√µes no arquivo JSON."""
    try:
        # Salva o dicion√°rio atualizado
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=4, ensure_ascii=False)
        st.success(f"Dicion√°rio de corre√ß√µes salvo com sucesso em: {filepath}")
    except Exception as e:
        st.error(f"Erro ao salvar dicion√°rio: {e}")

def normalize_address(address_string):
    """
    Normaliza a string de endere√ßo para uso como chave de busca no dicion√°rio
    e no fuzzy matching.
    """
    if pd.isna(address_string):
        return ""
    address_string = str(address_string).lower().strip()
    
    # Remove caracteres que N√ÉO s√£o alfanum√©ricos (\w), espa√ßo (\s) OU V√çRGULA (,)
    address_string = re.sub(r'[^\w\s,]', '', address_string) 
    
    # Substitui m√∫ltiplos espa√ßos por um √∫nico
    address_string = re.sub(r'\s+', ' ', address_string)
    
    # Substitui abrevia√ß√µes comuns para padroniza√ß√£o
    address_string = address_string.replace('rua', 'r').replace('avenida', 'av').replace('travessa', 'tr')
    
    return address_string

# --- Carregamento inicial do Dicion√°rio (uma vez por sess√£o) ---
if 'fixed_dict' not in st.session_state:
    st.session_state['fixed_dict'] = load_dictionary(DICTIONARY_FILE)

# --- CSS para garantir alinhamento √† esquerda em TEXT AREAS e Checkboxes ---
st.markdown("""
<style>
/* Alinha o texto de entrada na caixa de texto (√∫til para formul√°rios) */
.stTextArea [data-baseweb="base-input"] {
    text-align: left;
    font-family: monospace;
}
/* *** CSS FORTE: Garante que o conte√∫do e o t√≠tulo do st.text_area sejam alinhados √† esquerda *** */
div.stTextArea > label {
    text-align: left !important; /* T√≠tulo do text area */
}
/* For√ßa o alinhamento √† esquerda no campo de texto principal */
div[data-testid="stTextarea"] textarea {
    text-align: left !important; /* Conte√∫do do text area */
    font-family: monospace;
    white-space: pre-wrap; /* Garante que quebras de linha corretas */
}
/* Alinha os t√≠tulos e outros elementos em geral */
h1, h2, h3, h4, .stMarkdown {
    text-align: left !important;
}

</style>
""", unsafe_allow_html=True)
# --------------------------------------------------------------------------------------


# --- Configura√ß√µes Globais (Colunas) ---
COLUNA_ENDERECO = 'Destination Address'
COLUNA_SEQUENCE = 'Sequence'
COLUNA_LATITUDE = 'Latitude'
COLUNA_LONGITUDE = 'Longitude'

# ===============================================
# FUN√á√ïES DE PR√â-ROTEIRIZA√á√ÉO (CORRE√á√ÉO/AGRUPAMENTO)
# ===============================================

def limpar_endereco(endereco):
    """
    Normaliza o texto do endere√ßo para melhor compara√ß√£o.
    Reusa a fun√ß√£o normalize_address para consist√™ncia.
    """
    return normalize_address(endereco)


# Fun√ß√£o auxiliar para lidar com valores vazios no mode()
def get_most_common_or_empty(x):
    """
    Retorna o valor mais comum de uma S√©rie Pandas ou uma string vazia se todos forem NaN.
    """
    x_limpo = x.dropna()
    if x_limpo.empty:
        return ""
    return x_limpo.mode().iloc[0]


@st.cache_data(show_spinner=False)
def processar_e_corrigir_dados(df_entrada, limite_similaridade, fixed_dict):
    """
    Fun√ß√£o principal que aplica a corre√ß√£o FIXA, depois o fuzzy matching e o agrupamento.
    """
    colunas_essenciais = [COLUNA_ENDERECO, COLUNA_SEQUENCE, COLUNA_LATITUDE, COLUNA_LONGITUDE, 'Bairro', 'City', 'Zipcode/Postal code']
    for col in colunas_essenciais:
        if col not in df_entrada.columns:
            st.error(f"Erro: A coluna essencial '{col}' n√£o foi encontrada na sua planilha.")
            return None, None 

    df = df_entrada.copy()
    
    # Preenchimento inicial e convers√£o de tipo
    df['Bairro'] = df['Bairro'].astype(str).replace('nan', '', regex=False)
    df['City'] = df['City'].astype(str).replace('nan', '', regex=False)
    df['Zipcode/Postal code'] = df['Zipcode/Postal code'].astype(str).replace('nan', '', regex=False)
    df[COLUNA_LATITUDE] = pd.to_numeric(df[COLUNA_LATITUDE], errors='coerce')
    df[COLUNA_LONGITUDE] = pd.to_numeric(df[COLUNA_LONGITUDE], errors='coerce')


    # 1. Limpeza e Normaliza√ß√£o (Cria a chave de busca)
    df['Endereco_Limpo'] = df[COLUNA_ENDERECO].apply(limpar_endereco)
    
    # -----------------------------------------------------------------
    # 2. NOVO PASSO CR√çTICO: Aplica Corre√ß√£o do Dicion√°rio Fixo
    # -----------------------------------------------------------------
    
    correcoes_aplicadas = 0
    
    def apply_fixed_correction(row):
        """Sobrescreve Lat/Lng se a chave normalizada existir no dicion√°rio."""
        normalized_address = row['Endereco_Limpo']
        if normalized_address in fixed_dict:
            # Sobrescreve as coordenadas originais/geocodificadas com a corre√ß√£o manual
            row[COLUNA_LATITUDE] = fixed_dict[normalized_address]['lat']
            row[COLUNA_LONGITUDE] = fixed_dict[normalized_address]['lng']
            row['Source_Lat_Lng'] = 'FIXED_DICT'
            nonlocal correcoes_aplicadas # Permite modificar a vari√°vel externa
            correcoes_aplicadas += 1
        else:
            row['Source_Lat_Lng'] = 'ORIGINAL'
        return row

    # Aplica a fun√ß√£o linha por linha para sobrescrever as colunas de Lat/Lng
    df = df.apply(apply_fixed_correction, axis=1)
    
    st.info(f"**{correcoes_aplicadas}** coordenadas foram sobrescritas pelo Dicion√°rio Fixo de Corre√ß√µes.")
    # -----------------------------------------------------------------


    # Prepara coluna num√©rica de ordena√ß√£o 
    df['Sequence_Num'] = df[COLUNA_SEQUENCE].astype(str).str.replace('*', '', regex=False)
    df['Sequence_Num'] = pd.to_numeric(df['Sequence_Num'], errors='coerce').fillna(float('inf')).astype(float)


    # 3. Fuzzy Matching para Agrupamento 
    enderecos_unicos = df['Endereco_Limpo'].unique()
    mapa_correcao = {}
    progresso_bar = st.progress(0, text="Iniciando Fuzzy Matching para Agrupamento...")
    total_unicos = len(enderecos_unicos)

    if total_unicos == 0:
        progresso_bar.empty()
        st.warning("Nenhum endere√ßo encontrado para processar.")
        return None, None
    
    for i, end_principal in enumerate(enderecos_unicos):
        if end_principal not in mapa_correcao:
            matches = process.extract(
                end_principal, 
                enderecos_unicos, 
                scorer=fuzz.WRatio, 
                limit=None
            )
            grupo_matches = [
                match[0] for match in matches 
                if match[1] >= limite_similaridade
            ]
            
            df_grupo = df[df['Endereco_Limpo'].isin(grupo_matches)]
            endereco_oficial_original = get_most_common_or_empty(df_grupo[COLUNA_ENDERECO])
            if not endereco_oficial_original:
                 endereco_oficial_original = end_principal 
            
            for end_similar in grupo_matches:
                mapa_correcao[end_similar] = endereco_oficial_original
                
        progresso_bar.progress((i + 1) / total_unicos, text=f"Processando {i+1} de {total_unicos} endere√ßos √∫nicos...")
    
    progresso_bar.empty()
    st.success("Fuzzy Matching conclu√≠do!")

    # 4. Aplica√ß√£o do Endere√ßo Corrigido
    df['Endereco_Corrigido'] = df['Endereco_Limpo'].map(mapa_correcao)

    # 5. Agrupamento (POR ENDERE√áO CORRIGIDO E CIDADE)
    colunas_agrupamento = ['Endereco_Corrigido', 'City'] 
    
    df_agrupado = df.groupby(colunas_agrupamento).agg(
        # Agrupa as sequ√™ncias (que j√° cont√™m o *)
        Sequences_Agrupadas=(COLUNA_SEQUENCE, lambda x: ','.join(map(str, sorted(x, key=lambda y: int(re.sub(r'\*', '', str(y))) if re.sub(r'\*', '', str(y)).isdigit() else float('inf'))))), 
        Total_Pacotes=('Sequence_Num', lambda x: (x != float('inf')).sum()), 
        # AQUI usamos o valor que PODE TER SIDO CORRIGIDO PELO DICION√ÅRIO FIXO
        Latitude=(COLUNA_LATITUDE, 'first'),
        Longitude=(COLUNA_LONGITUDE, 'first'),
        
        Bairro_Agrupado=('Bairro', get_most_common_or_empty),
        Zipcode_Agrupado=('Zipcode/Postal code', get_most_common_or_empty),
        
        Min_Sequence=('Sequence_Num', 'min') 
        
    ).reset_index()

    # 6. ORDENA√á√ÉO
    df_agrupado = df_agrupado.sort_values(by='Min_Sequence').reset_index(drop=True)
    
    # 7. Formata√ß√£o do DF para o CIRCUIT 
    endereco_completo_circuit = (
        df_agrupado['Endereco_Corrigido'] + ', ' + 
        df_agrupado['Bairro_Agrupado'].str.strip()
    )
    endereco_completo_circuit = endereco_completo_circuit.str.replace(r',\s*,', ',', regex=True)
    
    notas_completas = (
        'Pacotes: ' + df_agrupado['Total_Pacotes'].astype(int).astype(str) + 
        ' | Cidade: ' + df_agrupado['City'] + 
        ' | CEP: ' + df_agrupado['Zipcode_Agrupado']
    )

    df_circuit = pd.DataFrame({
        'Order ID': df_agrupado['Sequences_Agrupadas'], 
        'Address': endereco_completo_circuit, 
        'Latitude': df_agrupado['Latitude'], 
        'Longitude': df_agrupado['Longitude'], 
        'Notes': notas_completas
    })
    
    return df_circuit, df


# ===============================================
# FUN√á√ïES DE P√ìS-ROTEIRIZA√á√ÉO (LIMPEZA P/ IMPRESS√ÉO)
# ===============================================

def processar_rota_para_impressao(df_input):
    """
    Processa o DataFrame da rota, extrai 'Ordem ID' da coluna 'Notes' e prepara para c√≥pia.
    
    RETORNA: 
    - df_final_geral: Lista de impress√£o de todos os pedidos.
    - df_volumosos: Lista de impress√£o APENAS dos pedidos que cont√™m '*' (volumosos).
    - df_nao_volumosos: Lista de impress√£o APENAS dos pedidos que N√ÉO cont√™m '*' (n√£o-volumosos).
    """
    coluna_notes_lower = 'notes'
    
    if coluna_notes_lower not in df_input.columns:
        raise KeyError(f"A coluna '{coluna_notes_lower}' n√£o foi encontrada.")
    
    df = df_input.copy()
    df[coluna_notes_lower] = df[coluna_notes_lower].astype(str)
    df = df.dropna(subset=[coluna_notes_lower]) 
    
    # 2. Separar a coluna Notes: Parte antes do ';' √© o Order ID (que cont√©m o *)
    df[coluna_notes_lower] = df[coluna_notes_lower].str.strip('"')
    
    # Divide a coluna na primeira ocorr√™ncia de ';'
    df_split = df[coluna_notes_lower].str.split(';', n=1, expand=True)
    df['Ordem ID'] = df_split[0].str.strip()
    df['Anota√ß√µes Completas'] = df_split[1].str.strip() if 1 in df_split.columns else ""
    
    
    # 3. Formata√ß√£o Final da Tabela (APENAS ID e ANOTA√á√ïES)
    df['Lista de Impress√£o'] = (
        df['Ordem ID'].astype(str) + 
        ' - ' + 
        df['Anota√ß√µes Completas'].astype(str)
    )
    
    # DataFrame FINAL GERAL
    df_final_geral = df[['Lista de Impress√£o', 'address']].copy() 
    
    # 4. FILTRAR VOLUMOSOS: Cria um DF separado APENAS para volumosos
    df_volumosos = df[df['Ordem ID'].str.contains(r'\*', regex=True)].copy()
    df_volumosos_impressao = df_volumosos[['Lista de Impress√£o', 'address']].copy()
    
    # 5. FILTRAR N√ÉO-VOLUMOSOS: Cria um DF separado APENAS para n√£o-volumosos
    df_nao_volumosos = df[~df['Ordem ID'].str.contains(r'\*', regex=True)].copy() 
    df_nao_volumosos_impressao = df_nao_volumosos[['Lista de Impress√£o', 'address']].copy()
    
    return df_final_geral, df_volumosos_impressao, df_nao_volumosos_impressao


# ===============================================
# INTERFACE PRINCIPAL
# ===============================================

st.title("üó∫Ô∏è Flow Completo Circuit (Pr√© e P√≥s-Roteiriza√ß√£o)")

# CRIA√á√ÉO DAS ABAS 
tab1, tab2, tab3 = st.tabs(["üöÄ Pr√©-Roteiriza√ß√£o (Importa√ß√£o)", "üóÉÔ∏è Gerenciar Dicion√°rio Fixo", "üìã P√≥s-Roteiriza√ß√£o (Impress√£o/C√≥pia)"])


# ----------------------------------------------------------------------------------
# ABA 1: PR√â-ROTEIRIZA√á√ÉO (CORRE√á√ÉO E IMPORTA√á√ÉO)
# ----------------------------------------------------------------------------------

with tab1:
    st.header("1. Gerar Arquivo para Importar no Circuit")
    st.caption("Esta etapa aplica corre√ß√µes fixas, corrige erros de digita√ß√£o e agrupa pedidos.")

    if 'df_original' not in st.session_state:
        st.session_state['df_original'] = None
    if 'volumoso_ids' not in st.session_state:
        st.session_state['volumoso_ids'] = set() 
    
    st.markdown("---")
    st.subheader("1.1 Carregar Planilha Original")

    uploaded_file_pre = st.file_uploader(
        "Arraste e solte o arquivo original (CSV/Excel) aqui:", 
        type=['csv', 'xlsx'],
        key="file_pre"
    )

    if uploaded_file_pre is not None:
        try:
            if uploaded_file_pre.name.endswith('.csv'):
                df_input_pre = pd.read_csv(uploaded_file_pre)
            else:
                df_input_pre = pd.read_excel(uploaded_file_pre, sheet_name=0)
            
            colunas_essenciais = [COLUNA_ENDERECO, COLUNA_SEQUENCE, COLUNA_LATITUDE, COLUNA_LONGITUDE, 'Bairro', 'City', 'Zipcode/Postal code']
            for col in colunas_essenciais:
                 if col not in df_input_pre.columns:
                     raise KeyError(f"A coluna '{col}' est√° faltando na sua planilha.")
            
            if st.session_state.get('last_uploaded_name') != uploaded_file_pre.name:
                 st.session_state['volumoso_ids'] = set()
                 st.session_state['last_uploaded_name'] = uploaded_file_pre.name


            st.session_state['df_original'] = df_input_pre.copy()
            st.success(f"Arquivo '{uploaded_file_pre.name}' carregado! Total de **{len(df_input_pre)}** registros.")
            
        except KeyError as ke:
             st.error(f"Erro de Coluna: {ke}")
             st.session_state['df_original'] = None
        except Exception as e:
            st.error(f"Ocorreu um erro ao carregar o arquivo. Verifique o formato. Erro: {e}")

    
    st.markdown("---")
    st.subheader("1.2 Marcar Pacotes Volumosos (Volumosos = *)")
    
    if st.session_state['df_original'] is not None:
        
        df_temp = st.session_state['df_original'].copy()
        df_temp['Order_Num'] = pd.to_numeric(df_temp[COLUNA_SEQUENCE], errors='coerce').fillna(float('inf'))
        
        ordens_originais_sorted = df_temp.sort_values('Order_Num')[COLUNA_SEQUENCE].astype(str).unique()
        
        def update_volumoso_ids(order_id, is_checked):
            if is_checked:
                st.session_state['volumoso_ids'].add(order_id)
            elif order_id in st.session_state['volumoso_ids']:
                st.session_state['volumoso_ids'].remove(order_id)

        st.caption("Marque os n√∫meros das ordens de servi√ßo que s√£o volumosas (ser√£o marcadas com *):")

        with st.container(height=300):
            for order_id in ordens_originais_sorted:
                
                is_checked = order_id in st.session_state['volumoso_ids']
                
                st.checkbox(
                    str(order_id), 
                    value=is_checked, 
                    key=f"vol_{order_id}",
                    on_change=update_volumoso_ids, 
                    args=(order_id, not is_checked) 
                )


        st.info(f"**{len(st.session_state['volumoso_ids'])}** pacotes marcados como volumosos.")
        
        st.markdown("---")
        st.subheader("1.3 Configurar e Processar")
        
        limite_similaridade_ajustado = st.slider(
            'Ajuste a Precis√£o do Corretor (Fuzzy Matching):',
            min_value=80,
            max_value=100,
            value=100, 
            step=1,
            help="Use 100% para garantir que endere√ßos na mesma rua com n√∫meros diferentes n√£o sejam agrupados (recomendado)."
        )
        st.info(f"O limite de similaridade est√° em **{limite_similaridade_ajustado}%**.")
        
        
        if st.button("üöÄ Iniciar Corretor e Agrupamento", key="btn_pre_final"):
            
            df_para_processar = st.session_state['df_original'].copy()
            df_para_processar[COLUNA_SEQUENCE] = df_para_processar[COLUNA_SEQUENCE].astype(str)
            
            for id_volumoso in st.session_state['volumoso_ids']:
                str_id_volumoso = str(id_volumoso)
                df_para_processar.loc[
                    df_para_processar[COLUNA_SEQUENCE] == str_id_volumoso, 
                    COLUNA_SEQUENCE
                ] = str_id_volumoso + '*'

            # Chama o processamento com o dicion√°rio fixo
            df_circuit, df_processado_completo = processar_e_corrigir_dados(
                df_para_processar, 
                limite_similaridade_ajustado, 
                st.session_state.fixed_dict
            )
            
            if df_circuit is not None:
                st.markdown("---")
                st.header("‚úÖ Resultado Conclu√≠do!")
                
                total_entradas = len(st.session_state['df_original'])
                total_agrupados = len(df_circuit)
                
                st.metric(
                    label="Endere√ßos √önicos Agrupados",
                    value=total_agrupados,
                    delta=f"-{total_entradas - total_agrupados} agrupados"
                )
                
                df_volumosos_separado = df_circuit[
                    df_circuit['Order ID'].astype(str).str.contains(r'\*', regex=True)
                ].copy()
                
                st.subheader("Arquivo para Roteiriza√ß√£o (Circuit)")
                st.dataframe(df_circuit, use_container_width=True)
                
                buffer_circuit = io.BytesIO()
                with pd.ExcelWriter(buffer_circuit, engine='openpyxl') as writer:
                    df_circuit.to_excel(writer, index=False, sheet_name='Circuit_Import_Geral')
                    
                    if not df_volumosos_separado.empty:
                        df_volumosos_separado.to_excel(writer, index=False, sheet_name='APENAS_VOLUMOSOS')
                        st.info(f"O arquivo de download conter√° uma aba extra com **{len(df_volumosos_separado)}** endere√ßos que incluem pacotes volumosos.")
                    else:
                        st.info("Nenhum pacote volumoso marcado. O arquivo de download ter√° apenas a aba principal.")
                        
                buffer_circuit.seek(0)
                
                st.download_button(
                    label="üì• Baixar ARQUIVO PARA CIRCUIT",
                    data=buffer_circuit,
                    file_name="Circuit_Import_FINAL_MARCADO.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_excel_circuit"
                )

    elif uploaded_file_pre is None and st.session_state.get('df_original') is not None:
        st.session_state['df_original'] = None
        st.session_state['volumoso_ids'] = set()
        st.session_state['last_uploaded_name'] = None
        st.rerun() 


# ----------------------------------------------------------------------------------
# ABA 2: GERENCIAMENTO DO DICION√ÅRIO FIXO
# ----------------------------------------------------------------------------------

with tab2:
    st.header("üóÉÔ∏è Gerenciar Dicion√°rio de Corre√ß√µes Fixas")
    st.caption("Corre√ß√µes salvas aqui ser√£o aplicadas automaticamente ANTES do Fuzzy Matching.")
    
    
    # --- 2.1 Formul√°rio de Cadastro ---
    st.subheader("2.1 Adicionar Nova Corre√ß√£o")

    with st.form("form_add_correction", clear_on_submit=True):
        
        address_input = st.text_input(
            "Endere√ßo Exato Digitado (Chave)",
            placeholder="Ex: Rua das Palmeiras, 63",
            help="Insira o texto EXATO que o cliente digitou. A busca ser√° feita com a vers√£o normalizada."
        )

        col_lat, col_lng = st.columns(2)
        lat_input = col_lat.text_input("Latitude Corrigida", placeholder="-23.55000")
        lng_input = col_lng.text_input("Longitude Corrigida", placeholder="-46.63300")
        
        submitted = st.form_submit_button("‚ûï Adicionar Corre√ß√£o e Salvar")

        if submitted:
            if not address_input or not lat_input or not lng_input:
                st.error("Preencha todos os campos: Endere√ßo, Latitude e Longitude.")
            else:
                try:
                    lat_value = float(lat_input)
                    lng_value = float(lng_input)
                    
                    normalized_key = normalize_address(address_input)
                    
                    if normalized_key in st.session_state.fixed_dict:
                        st.warning(f"A chave '{normalized_key}' j√° existe e ser√° atualizada!")
                    
                    st.session_state.fixed_dict[normalized_key] = {
                        "lat": lat_value,
                        "lng": lng_value,
                        "original_string": address_input.strip() 
                    }
                    
                    save_dictionary(DICTIONARY_FILE, st.session_state.fixed_dict)
                    st.rerun()
                    
                except ValueError:
                    st.error("Latitude e Longitude devem ser n√∫meros v√°lidos.")
    
    st.markdown("---")
    
    # --- 2.2 Lista de Corre√ß√µes Ativas ---
    st.subheader(f"2.2 Corre√ß√µes Ativas ({len(st.session_state.fixed_dict)} entradas)")
    
    if st.session_state.fixed_dict:
        
        data_for_display = []
        for key, data in st.session_state.fixed_dict.items():
            data_for_display.append({
                "Chave Normalizada": key,
                "Endere√ßo Original": data.get('original_string', key),
                "Latitude": data['lat'],
                "Longitude": data['lng']
            })
        
        df_display = pd.DataFrame(data_for_display)
        
        st.dataframe(df_display, use_container_width=True, height=400)
        
        buffer_json = io.StringIO()
        json.dump(st.session_state.fixed_dict, buffer_json, indent=4, ensure_ascii=False)
        buffer_json.seek(0)
        
        st.download_button(
            label="‚¨áÔ∏è Baixar JSON do Dicion√°rio",
            data=buffer_json.read(),
            file_name=DICTIONARY_FILE,
            mime="application/json",
            key="download_dict_json"
        )
        
        def clear_dictionary():
            st.session_state.fixed_dict = {}
            save_dictionary(DICTIONARY_FILE, st.session_state.fixed_dict)
        
        if st.button("üî¥ Limpar Todo o Dicion√°rio Fixo", type="secondary"):
            st.warning("Tem certeza? Isso apagar√° TODAS as corre√ß√µes salvas.")
            if st.button("SIM, APAGAR DEFINITIVAMENTE", type="primary"):
                clear_dictionary()
                st.rerun()
                
    else:
        st.info("Nenhuma corre√ß√£o fixa cadastrada. Use o formul√°rio acima para adicionar a primeira.")


# ----------------------------------------------------------------------------------
# ABA 3: P√ìS-ROTEIRIZA√á√ÉO (LIMPEZA P/ IMPRESS√ÉO E SEPARA√á√ÉO DE VOLUMOSOS)
# ----------------------------------------------------------------------------------

with tab3:
    st.header("2. Limpar Sa√≠da do Circuit para Impress√£o")
    st.warning("‚ö†Ô∏è Aten√ß√£o: Use o arquivo CSV/Excel que foi gerado *ap√≥s a convers√£o* do PDF da rota do Circuit.")

    st.markdown("---")
    st.subheader("2.1 Carregar Arquivo da Rota")

    uploaded_file_pos = st.file_uploader(
        "Arraste e solte o arquivo da rota do Circuit aqui (CSV/Excel):", 
        type=['csv', 'xlsx'],
        key="file_pos"
    )

    sheet_name_default = "Table 3" 
    sheet_name = sheet_name_default
    
    df_final_geral = None 
    df_volumosos_impressao = None 
    df_nao_volumosos_impressao = None 
    
    copia_data_geral = "Nenhum arquivo carregado ou nenhum dado v√°lido encontrado ap√≥s o processamento."
    copia_data_volumosos = "Nenhum pacote volumoso encontrado na rota."
    copia_data_nao_volumosos = "Nenhum pacote n√£o-volumoso encontrado na rota."

    if uploaded_file_pos is not None and uploaded_file_pos.name.endswith('.xlsx'):
        sheet_name = st.text_input(
            "Seu arquivo √© um Excel (.xlsx). Digite o nome da aba com os dados da rota (ex: Table 3):", 
            value=sheet_name_default
        )

    if uploaded_file_pos is not None:
        try:
            if uploaded_file_pos.name.endswith('.csv'):
                df_input_pos = pd.read_csv(uploaded_file_pos)
            else:
                df_input_pos = pd.read_excel(uploaded_file_pos, sheet_name=sheet_name)
            
            df_input_pos.columns = df_input_pos.columns.str.strip() 
            df_input_pos.columns = df_input_pos.columns.str.lower()

            st.success(f"Arquivo '{uploaded_file_pos.name}' carregado! Total de **{len(df_input_pos)}** registros.")
            
            df_final_geral, df_volumosos_impressao, df_nao_volumosos_impressao = processar_rota_para_impressao(df_input_pos)
            
            if df_final_geral is not None and not df_final_geral.empty:
                st.markdown("---")
                st.subheader("2.2 Resultado Final (Lista de Impress√£o GERAL)")
                st.caption("A tabela abaixo √© apenas para visualiza√ß√£o. Use a √°rea de texto ou o download para c√≥pia r√°pida.")
                
                df_visualizacao_geral = df_final_geral.copy()
                df_visualizacao_geral.columns = ['ID(s) Agrupado - Anota√ß√µes', 'Endere√ßo da Parada']
                st.dataframe(df_visualizacao_geral, use_container_width=True)

                copia_data_geral = '\n'.join(df_final_geral['Lista de Impress√£o'].astype(str).tolist())
                
                
                st.markdown("---")
                st.header("‚úÖ Lista de Impress√£o APENAS N√ÉO-VOLUMOSOS")
                
                if not df_nao_volumosos_impressao.empty:
                    st.success(f"Foram encontrados **{len(df_nao_volumosos_impressao)}** endere√ßos com pacotes N√ÉO-volumosos nesta rota.")
                    
                    df_visualizacao_nao_vol = df_nao_volumosos_impressao.copy()
                    df_visualizacao_nao_vol.columns = ['ID(s) Agrupado - Anota√ß√µes', 'Endere√ßo da Parada']
                    st.dataframe(df_visualizacao_nao_vol, use_container_width=True)
                    
                    copia_data_nao_volumosos = '\n'.join(df_nao_volumosos_impressao['Lista de Impress√£o'].astype(str).tolist())
                    
                else:
                    st.info("Todos os pedidos nesta rota est√£o marcados como volumosos ou a lista est√° vazia.")
                    
                st.markdown("---")
                st.header("üì¶ Lista de Impress√£o APENAS VOLUMOSOS")
                
                if not df_volumosos_impressao.empty:
                    st.warning(f"Foram encontrados **{len(df_volumosos_impressao)}** endere√ßos com pacotes volumosos nesta rota.")
                    
                    df_visualizacao_vol = df_volumosos_impressao.copy()
                    df_visualizacao_vol.columns = ['ID(s) Agrupado - Anota√ß√µes', 'Endere√ßo da Parada']
                    st.dataframe(df_visualizacao_vol, use_container_width=True)
                    
                    copia_data_volumosos = '\n'.join(df_volumosos_impressao['Lista de Impress√£o'].astype(str).tolist())
                    
                else:
                    st.info("Nenhum pedido volumoso detectado nesta rota (nenhum '*' encontrado no Order ID).")


            else:
                 copia_data_geral = "O arquivo foi carregado, mas a coluna 'Notes' estava vazia ou o processamento n√£o gerou resultados. Verifique o arquivo de rota do Circuit."


        except KeyError as ke:
             if "Table 3" in str(ke) or "Sheet" in str(ke):
                st.error(f"Erro de Aba: A aba **'{sheet_name}'** n√£o foi encontrada no arquivo Excel. Verifique o nome da aba.")
             elif 'notes' in str(ke):
                 st.error(f"Erro de Coluna: A coluna 'notes' n√£o foi encontrada. Verifique se o arquivo da rota est√° correto.")
             elif 'address' in str(ke):
                 st.error(f"Erro de Coluna: A coluna 'address' n√£o foi encontrada. Verifique o arquivo de rota.")
             else:
                 st.error(f"Ocorreu um erro de coluna ou formato. Erro: {e}")
        except Exception as e:
            st.error(f"Ocorreu um erro ao processar o arquivo. Verifique se o arquivo da rota (PDF convertido) est√° no formato CSV ou Excel. Erro: {e}")
            
    
    if uploaded_file_pos is not None:
        
        st.markdown("### 2.3 Copiar para a √Årea de Transfer√™ncia (Lista GERAL)")
        st.info("Para copiar: **Selecione todo o texto** abaixo (Ctrl+A / Cmd+A) e pressione **Ctrl+C / Cmd+C**.")
        
        st.text_area(
            "Conte√∫do da Lista de Impress√£o GERAL (Alinhado √† Esquerda):", 
            copia_data_geral, 
            height=300,
            key="text_area_geral"
        )

        if not df_nao_volumosos_impressao.empty if df_nao_volumosos_impressao is not None else False:
            st.markdown("### 2.4 Copiar para a √Årea de Transfer√™ncia (APENAS N√ÉO-Volumosos)")
            st.success("Lista Filtrada: Cont√©m **somente** os endere√ßos com pacotes **N√ÉO-volumosos** (sem o '*').")
            
            st.text_area(
                "Conte√∫do da Lista de Impress√£o N√ÉO-VOLUMOSOS (Alinhado √† Esquerda):", 
                copia_data_nao_volumosos, 
                height=150,
                key="text_area_nao_volumosos"
            )
        
        if not df_volumosos_impressao.empty if df_volumosos_impressao is not None else False:
            st.markdown("### 2.5 Copiar para a √Årea de Transfer√™ncia (APENAS Volumosos)")
            st.warning("Lista Filtrada: Cont√©m **somente** os endere√ßos com pacotes volumosos.")
            
            st.text_area(
                "Conte√∫do da Lista de Impress√£o VOLUMOSOS (Alinhado √† Esquerda):", 
                copia_data_volumosos, 
                height=150,
                key="text_area_volumosos"
            )
        
        
        if df_final_geral is not None and not df_final_geral.empty:
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer: 
                df_final_geral[['Lista de Impress√£o']].to_excel(writer, index=False, sheet_name='Lista Impressao Geral')
                
                if df_nao_volumosos_impressao is not None and not df_nao_volumosos_impressao.empty:
                    df_nao_volumosos_impressao[['Lista de Impress√£o']].to_excel(writer, index=False, sheet_name='Lista Nao Volumosos')
                    
                if df_volumosos_impressao is not None and not df_volumosos_impressao.empty:
                    df_volumosos_impressao[['Lista de Impress√£o']].to_excel(writer, index=False, sheet_name='Lista Volumosos')
                    
            buffer.seek(0)
            
            st.download_button(
                label="üì• Baixar Lista Limpa (Excel) - Geral + Separadas",
                data=buffer,
                file_name="Lista_Ordem_Impressao_FINAL.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                help="Baixe este arquivo. Ele cont√©m tr√™s abas: a lista geral, a lista de n√£o-volumosos e a lista de volumosos.",
                key="download_list"
            )
